{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset,DatasetDict,load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from itertools import islice\n",
    "import copy\n",
    "from torchmetrics.retrieval import RetrievalMAP, RetrievalPrecision\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/Users/aakashagarwal/Downloads/ir_assignment2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x128cb1010>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydataset = \"evanarlian/imagenet_1k_resized_256\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea06f7e99d85473399aadd5812d7a0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b2bce0bf2e42f6ae163a969f0d1c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accb147b3d8e4d51aef9bc77b6b5409e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(mydataset)\n",
    "ds = ds.rename_column(\"image\", \"img\")\n",
    "\n",
    "ds = DatasetDict({\n",
    "    'train': ds['train'],\n",
    "    'test': ds['val']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/Users/aakashagarwal/Downloads/ir_assignment2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_train = ds['train'].select(range(1000))\n",
    "# ds_test = ds['test'].select(range(100))\n",
    "\n",
    "# ds = DatasetDict({\n",
    "#     'train': ds_train,\n",
    "#     'test': ds_test\n",
    "# })\n",
    "\n",
    "# ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"google/vit-large-patch32-384\",use_fast=True)\n",
    "model = AutoModelForImageClassification.from_pretrained(\"google/vit-large-patch32-384\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((384, 384)),  # Resize images to a consistent size\n",
    "        transforms.ToTensor(),           # Convert PIL images to tensors\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# Define a function to process and extract features from each image\n",
    "def extract_features(batch):\n",
    "    imgs = batch['img']  # This will now be a list of images in a batch\n",
    "\n",
    "    # Preprocess each image in the batch\n",
    "    img_tensors = [transform(img).unsqueeze(0).to(device) for img in imgs]  # Add batch dimension and move to device\n",
    "    img_tensors = torch.cat(img_tensors, dim=0)  # Concatenate to create a batch tensor\n",
    "\n",
    "    inputs = {'pixel_values': img_tensors}  # Adjust for model input (assuming using Hugging Face models)\n",
    "\n",
    "    # Forward pass through the model to get features\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "    hidden_states = outputs.hidden_states  # List of all hidden states\n",
    "\n",
    "    # Extract the final hidden state\n",
    "    final_hidden_state = hidden_states[-1]  # Shape: [batch_size, num_patches, hidden_size]\n",
    "    \n",
    "    # Optionally, pool the features\n",
    "    pooled_features = final_hidden_state.mean(dim=1)  # Shape: [batch_size, hidden_size]\n",
    "    \n",
    "    # Return the features as a new column for the batch\n",
    "    return {\"features\": pooled_features.cpu().numpy()}  # \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create features of train data or load from saved file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features file already exists at /Users/aakashagarwal/Downloads/ir_assignment2/features/imagenet1k/vit_large/. Loading features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a5d8a43d1645f09be8d2153401fd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "output_dir = main_path+ f\"features/imagenet1k/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"vit_large/\")  # Saving in Arrow format\n",
    "\n",
    "# Check if features already exist\n",
    "if os.path.exists(output_file):\n",
    "    print(f\"Features file already exists at {output_file}. Loading features...\")\n",
    "    # Load existing features\n",
    "    ds_feature = load_from_disk(output_file)\n",
    "else:\n",
    "    print(\"Features file does not exist. Extracting features...\")\n",
    "\n",
    "    # Use `map` to apply the feature extraction across the entire dataset\n",
    "    ds_feature = ds.map(extract_features, batched=True, batch_size=64)\n",
    "\n",
    "    # Save the dataset with the new features to disk\n",
    "    ds_feature.save_to_disk(output_file)  # Saving in the Arrow format\n",
    "    print(\"Features saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_feature\n",
    "ds_feature = ds_feature.rename_column(\"labels\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    # Define the transformations you want to apply to the images\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize images to a consistent size\n",
    "        transforms.ToTensor(),           # Convert PIL images to tensors\n",
    "    ])\n",
    "\n",
    "    # Extracting each field from the batch\n",
    "    index = [item['index'] for item in batch]\n",
    "    # images = [transform(item['img']) for item in batch]  # Load and transform images\n",
    "    labels = torch.tensor([item['label'] for item in batch])          # Convert labels to a tensor\n",
    "    features = [torch.tensor(item['features']) for item in batch]     # Convert features to tensors\n",
    "    \n",
    "    # Return a dictionary with batched data\n",
    "    return {\n",
    "        'index': index,\n",
    "        # 'img': torch.stack(images),    # Stack image tensors into a single tensor\n",
    "        'label': labels,\n",
    "        'features': torch.stack(features),  # Stack feature tensors into a single tensor\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_collate(batch):\n",
    "    # Define the transformations you want to apply to the images\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize images to a consistent size\n",
    "        transforms.ToTensor(),           # Convert PIL images to tensors\n",
    "    ])\n",
    "\n",
    "    # Extracting each field from the batch\n",
    "    index = [item['index'] for item in batch]\n",
    "    images = [transform(item['img']) for item in batch]  # Load and transform images\n",
    "    labels = torch.tensor([item['label'] for item in batch])          # Convert labels to a tensor\n",
    "    features = [torch.tensor(item['features']) for item in batch]     # Convert features to tensors\n",
    "    \n",
    "    # Return a dictionary with batched data\n",
    "    return {\n",
    "        'index': index,\n",
    "        'img': torch.stack(images),    # Stack image tensors into a single tensor\n",
    "        'label': labels,\n",
    "        'features': torch.stack(features),  # Stack feature tensors into a single tensor\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(ds_feature['train'], batch_size=64, shuffle=True,collate_fn=custom_collate)\n",
    "test_dataloader = DataLoader(ds_feature['test'], batch_size=64, shuffle=True,collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4334, 2579, 4290, 2130, 4901, 2570, 4533, 2299, 2250, 3946, 4444, 2047, 2395, 2980, 104, 2040, 3374, 2973, 352, 1682, 3621, 3129, 2499, 3020, 2826, 3974, 1247, 4998, 2341, 3292, 423, 3449, 4273, 1609, 605, 992, 123, 1277, 2498, 4037, 3930, 3615, 3156, 1779, 4608, 2812, 1667, 2100, 3123, 3207, 2208, 995, 2928, 4994, 2700, 885, 4677, 4699, 1872, 3995, 3252, 4565, 3148, 3858]\n"
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(test_dataloader):\n",
    "    if i ==19:\n",
    "        print(batch['index'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader to random a random batch, shuffle=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_train_dataloader = DataLoader(\n",
    "    ds_feature['train'], batch_size=64, shuffle=True, collate_fn=random_collate, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get radom batch to sample negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_batch():\n",
    "    random_train_dataloader = DataLoader(\n",
    "        ds_feature['train'], batch_size=64, shuffle=True, collate_fn=custom_collate, pin_memory=True\n",
    "    )\n",
    "    # Get the first batch from the DataLoader\n",
    "    first_batch = next(iter(random_train_dataloader))\n",
    "    return first_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HashNetwok Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HashNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hash_bits):\n",
    "        super(HashNetwork, self).__init__()\n",
    "        \n",
    "        # Define the hashing network layers\n",
    "        self.hashing_network = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # Increased dropout rate for regularization\n",
    "            nn.Linear(input_dim, input_dim // 2, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim // 2, input_dim // 4, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim // 4, hash_bits, bias=True),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # Initialize the loss coefficients as a learnable parameter\n",
    "        self.loss_coefficients = nn.Parameter(torch.FloatTensor(3))\n",
    "        nn.init.uniform_(self.loss_coefficients, 0.01, 0.1)  # Use uniform initialization for loss coefficients\n",
    "\n",
    "        # Initialize network weights using Xavier initialization\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for module in self.hashing_network:\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)  # Apply Xavier initialization to weights\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)  # Initialize biases to zero\n",
    "\n",
    "        # Normalize the loss coefficients to ensure they sum to 1 initially\n",
    "        self.loss_coefficients.data /= self.loss_coefficients.data.sum()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.hashing_network(x)\n",
    "\n",
    "    def get_loss_coefficients(self):\n",
    "        # Apply softmax to ensure they sum to 1\n",
    "        return nn.functional.softmax(self.loss_coefficients, dim=0)\n",
    "\n",
    "    def clamp_and_normalize_loss_coefficients(self, min_value=0.01):\n",
    "        # Clamp the coefficients to be at least `min_value`\n",
    "        self.loss_coefficients.data = torch.clamp(self.loss_coefficients.data, min=min_value)\n",
    "        \n",
    "        # Normalize the coefficients to sum to 1\n",
    "        self.loss_coefficients.data /= torch.sum(self.loss_coefficients.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_function(model, batch_features, batch_labels, random_batch_features, random_batch_labels, \n",
    "                         use_hyperparameter=True, alpha=0.01, beta=0.01, gamma=0.98):\n",
    "    # Forward pass: Get hash codes from model\n",
    "    batch_size = len(batch_labels)\n",
    "    hash_codes = model(batch_features.to(device))  # shape: (batch_size, output_dim)\n",
    "    random_hash_codes = model(random_batch_features.to(device))\n",
    "    \n",
    "    # 1. Bit balance term\n",
    "    balance_loss = torch.mean(torch.abs(torch.sum(hash_codes, dim=1)))\n",
    "    \n",
    "    # 2. No sitting on the fence term\n",
    "    # print(torch.abs(hash_codes))\n",
    "    # print(\"###############\")\n",
    "    # print(torch.abs(hash_codes) - 1)\n",
    "    # print(\"######################\")\n",
    "    # print(torch.norm(torch.abs(hash_codes) - 1, p=1, dim=1))\n",
    "    # fence_loss = torch.mean(torch.sum(torch.abs(torch.abs(hash_codes) - 1),dim=1))\n",
    "    fence_loss= torch.mean(torch.norm(torch.abs(hash_codes) - 1, p=1, dim=1))  # Apply the L1 norm\n",
    "\n",
    "\n",
    "     \n",
    "    # Create lists to store negative pairs\n",
    "    negative_pairs = []\n",
    "    for i in range(batch_size):\n",
    "        for j in range(batch_size):\n",
    "            if batch_labels[i] != random_batch_labels[j]:\n",
    "                similarity = torch.nn.functional.cosine_similarity(\n",
    "                    hash_codes[i].unsqueeze(0), random_hash_codes[j].unsqueeze(0))\n",
    "                negative_pairs.append((i, j, similarity.item()))\n",
    "\n",
    "    negative_pairs = sorted(negative_pairs, key=lambda x: x[2])\n",
    "    negative_pairs = negative_pairs[:16]  # take top 16 negative pairs\n",
    "    \n",
    "    \n",
    "    weak_supervision_loss = 0\n",
    "    # Calculate the loss for sampled negative pairs\n",
    "    if negative_pairs:\n",
    "        weak_supervision_loss = torch.sum(\n",
    "            torch.stack([torch.abs(torch.dot(hash_codes[u], hash_codes[v])) for u, v, _ in negative_pairs])\n",
    "        ) / len(negative_pairs)\n",
    "    \n",
    "    # Get loss coefficients\n",
    "    if use_hyperparameter:\n",
    "        gamma = 1 - alpha - beta\n",
    "    else:\n",
    "        alpha, beta, gamma = model.get_loss_coefficients()\n",
    "\n",
    "    # Calculate total loss\n",
    "    total_loss = alpha * balance_loss + beta * fence_loss + gamma * weak_supervision_loss\n",
    "    \n",
    "    return total_loss, balance_loss, fence_loss, weak_supervision_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, dataloader, optimizer, use_hyperparameter,alpha, beta, gamma,num_epochs=1, save_interval=1):\n",
    "    model.train()  # set model to training mode\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Create a progress bar for the current epoch\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch [{epoch + 1}/{num_epochs}]\", leave=False)\n",
    "        \n",
    "        for idx, batch in enumerate(progress_bar):\n",
    "            batch_features = batch['features'].to(device)  # features from your dataset\n",
    "            batch_labels = batch['label'].to(device)  # labels for the images\n",
    "            # Random batch\n",
    "            random_batch = get_random_batch()\n",
    "            random_batch_features, random_batch_labels = random_batch['features'],random_batch['label']\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Calculate your custom loss\n",
    "            loss, balance_loss, fence_loss, weak_supervision_loss = custom_loss_function(model, batch_features, batch_labels, random_batch_features, random_batch_labels,use_hyperparameter, alpha, beta, gamma)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Clamp and normalize loss coefficients\n",
    "            model.clamp_and_normalize_loss_coefficients(min_value=0.01)\n",
    "\n",
    "            # Track running loss\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Update progress bar with loss values\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': loss.item(),\n",
    "                'balance_loss': balance_loss.item(),\n",
    "                'fence_loss': fence_loss.item(),\n",
    "                'weak_loss': weak_supervision_loss.item()\n",
    "            })\n",
    "            \n",
    "        for i,j in model.named_parameters():\n",
    "            if i == 'loss_coefficients':\n",
    "                print(j)\n",
    "        \n",
    "        # Average loss per epoch\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Save the model every `save_interval` epochs\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            model_save_path = f\"imagenet_neural_lsh_1_epoch_{epoch + 1}.pth\"\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Model saved at {model_save_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1024  # Example input dimension\n",
    "hash_bits = 16   # Example number of hash bits\n",
    "alpha=0.01\n",
    "beta=0.01\n",
    "gamma=1- alpha-beta\n",
    "# Instantiate the model\n",
    "model = HashNetwork(input_dim=input_dim, hash_bits=hash_bits).to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the path to the saved model\n",
    "# model = HashNetwork(input_dim=input_dim, hash_bits=hash_bits).to(device)\n",
    "\n",
    "# model_load_path = \"imagenet_neural_lsh_1_epoch_10.pth\"\n",
    "\n",
    "# state_dict = torch.load(model_load_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# # Load the state dictionary into the model\n",
    "# model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.1206, 0.4311, 0.4483], requires_grad=True)\n",
      "Epoch [1/10], Loss: 0.2667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.1206, 0.4311, 0.4483], requires_grad=True)\n",
      "Epoch [2/10], Loss: 0.1961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.1206, 0.4311, 0.4483], requires_grad=True)\n",
      "Epoch [3/10], Loss: 0.1792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.1206, 0.4311, 0.4483], requires_grad=True)\n",
      "Epoch [4/10], Loss: 0.1708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.1206, 0.4311, 0.4483], requires_grad=True)\n",
      "Epoch [5/10], Loss: 0.1659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.1206, 0.4311, 0.4483], requires_grad=True)\n",
      "Epoch [6/10], Loss: 0.1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.1206, 0.4311, 0.4483], requires_grad=True)\n",
      "Epoch [7/10], Loss: 0.1610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.1206, 0.4311, 0.4483], requires_grad=True)\n",
      "Epoch [8/10], Loss: 0.1599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                    \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model(model, train_dataloader, optimizer, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,use_hyperparameter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, alpha\u001b[38;5;241m=\u001b[39malpha, beta\u001b[38;5;241m=\u001b[39mbeta, gamma\u001b[38;5;241m=\u001b[39mgamma)\n",
      "Cell \u001b[0;32mIn[42], line 14\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, optimizer, use_hyperparameter, alpha, beta, gamma, num_epochs, save_interval)\u001b[0m\n\u001b[1;32m     12\u001b[0m batch_labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# labels for the images\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Random batch\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m random_batch \u001b[38;5;241m=\u001b[39m get_random_batch()\n\u001b[1;32m     15\u001b[0m random_batch_features, random_batch_labels \u001b[38;5;241m=\u001b[39m random_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m],random_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "Cell \u001b[0;32mIn[39], line 6\u001b[0m, in \u001b[0;36mget_random_batch\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m random_train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m      3\u001b[0m     ds_feature[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcustom_collate, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Get the first batch from the DataLoader\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m first_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(random_train_dataloader))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m first_batch\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:672\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:620\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/sampler.py:288\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m    287\u001b[0m idx_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler:\n\u001b[1;32m    289\u001b[0m     batch[idx_in_batch] \u001b[38;5;241m=\u001b[39m idx\n\u001b[1;32m    290\u001b[0m     idx_in_batch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/sampler.py:168\u001b[0m, in \u001b[0;36mRandomSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n):\n\u001b[0;32m--> 168\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandperm(n, generator\u001b[38;5;241m=\u001b[39mgenerator)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandperm(n, generator\u001b[38;5;241m=\u001b[39mgenerator)\u001b[38;5;241m.\u001b[39mtolist()[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m%\u001b[39m n]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, optimizer, num_epochs=10,use_hyperparameter=True, alpha=alpha, beta=beta, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at imagenet_neural_lsh_1_epoch_8.pth\n"
     ]
    }
   ],
   "source": [
    "model_save_path = f\"imagenet_neural_lsh_1_epoch_{8}.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved at {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on HASH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define L and J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3  # number of hash tables\n",
    "J = 12 # number of bits to randomly sample from hash length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hash Code on training data after training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 20019/20019 [10:22<00:00, 32.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 20019/20019 [08:44<00:00, 38.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  33%|███▎      | 6532/20019 [02:56<06:04, 36.95it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m random_positions \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(hash_bits), J)\n\u001b[1;32m      9\u001b[0m position_list\u001b[38;5;241m.\u001b[39mappend(random_positions)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Batches\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     12\u001b[0m     \n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Extract features and compute hash code\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     feature \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m     hash_value \u001b[38;5;241m=\u001b[39m model(feature)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/datasets/arrow_dataset.py:2746\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: List) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[1;32m   2745\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2746\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(keys)\n\u001b[1;32m   2747\u001b[0m     n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[1;32m   2748\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/datasets/arrow_dataset.py:2742\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2740\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2741\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2742\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(key)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/datasets/arrow_dataset.py:2727\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2725\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2726\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2727\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[1;32m   2728\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[1;32m   2729\u001b[0m )\n\u001b[1;32m   2730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/datasets/formatting/formatting.py:647\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    646\u001b[0m     pa_table_to_format \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mdrop(col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m pa_table\u001b[38;5;241m.\u001b[39mcolumn_names \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m format_columns)\n\u001b[0;32m--> 647\u001b[0m     formatted_output \u001b[38;5;241m=\u001b[39m formatter(pa_table_to_format, query_type\u001b[38;5;241m=\u001b[39mquery_type)\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_all_columns:\n\u001b[1;32m    649\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_output, MutableMapping):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/datasets/formatting/formatting.py:407\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_batch(pa_table)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/datasets/formatting/formatting.py:455\u001b[0m, in \u001b[0;36mPythonFormatter.format_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyBatch(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 455\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_batch(pa_table)\n\u001b[1;32m    456\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_batch(batch)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/datasets/formatting/formatting.py:151\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pa_table\u001b[38;5;241m.\u001b[39mto_pydict()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hash_dict_list = []\n",
    "position_list = []\n",
    "\n",
    "# Iterate through the dataset\n",
    "for i in range(L):\n",
    "    hash_dict = dict()\n",
    "     # Randomly select J unique positions from the range of the hash_length\n",
    "    random_positions = random.sample(range(hash_bits), J)\n",
    "    position_list.append(random_positions)\n",
    "    \n",
    "    for batch_idx, data in enumerate(tqdm(train_dataloader, desc=\"Processing Batches\")):\n",
    "        \n",
    "        # Extract features and compute hash code\n",
    "        feature = data['features'].to(device)\n",
    "        hash_value = model(feature)\n",
    "        hash_code = torch.where(hash_value > 0, 1, 0)\n",
    "        \n",
    "        # Convert the hash code tensor to a list of tuples for dictionary key compatibility\n",
    "        hash_code_list = hash_code.tolist()\n",
    "\n",
    "       \n",
    "        # Iterate through each image and label in the batch\n",
    "        for j in range(len(hash_code_list)):\n",
    "            # Create a unique key from the hash code of each image\n",
    "            hash_code_key = [hash_code_list[j][pos] for pos in random_positions]\n",
    "            hash_code_key = tuple(hash_code_key)\n",
    "            # Initialize the list if this hash code key is not yet in the dictionary\n",
    "            if hash_code_key not in hash_dict:\n",
    "                hash_dict[hash_code_key] = []\n",
    "            \n",
    "            # Append the tuple (batch index, image index, label) to the list of this hash code key\n",
    "            val = [data['index'][j], data['label'][j].item()]\n",
    "            hash_dict[hash_code_key].append(val)\n",
    "    print(len(hash_dict.keys()))\n",
    "    hash_dict_list.append(hash_dict)\n",
    "    \n",
    "\n",
    "# You now have a list of new hash tables with sampled bits, and a list of their corresponding positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 0,  ..., 1, 0, 0],\n",
      "        [0, 0, 1,  ..., 1, 0, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 0, 1,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 1, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, data in enumerate(tqdm(train_dataloader, desc=\"Processing Batches\")):\n",
    "    \n",
    "    # Extract features and compute hash code\n",
    "    feature = data['features'].to(device)\n",
    "    hash_value = model(feature)\n",
    "    hash_code = torch.where(hash_value > 0, 1, 0)\n",
    "    print(hash_code)\n",
    "    \n",
    "    # Convert the hash code tensor to a list of tuples for dictionary key compatibility\n",
    "    hash_code_list = hash_code.tolist()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 4, 5, 1, 10, 7, 14, 8, 15, 6],\n",
       " [4, 6, 15, 5, 2, 3, 7, 14, 10, 0],\n",
       " [1, 13, 14, 6, 10, 8, 11, 0, 7, 3],\n",
       " [14, 2, 10, 8, 11, 1, 6, 13, 4, 0],\n",
       " [0, 8, 13, 12, 15, 14, 2, 10, 3, 5],\n",
       " [5, 14, 10, 0, 2, 15, 9, 11, 3, 13],\n",
       " [5, 9, 11, 3, 10, 7, 0, 14, 8, 1],\n",
       " [2, 8, 1, 0, 12, 5, 14, 9, 3, 13],\n",
       " [13, 1, 3, 5, 2, 14, 6, 8, 15, 0],\n",
       " [15, 5, 2, 0, 11, 7, 10, 6, 1, 14]]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of buckets in each hash table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0, 0, 1, 1, 1, 1, 1, 1) [[48769, 8], [29304, 7], [17468, 4], [32509, 6], [24445, 1], [12664, 3], [7649, 4], [42964, 0], [5823, 2], [21998, 3], [46932, 6], [1079, 1], [38356, 5], [29723, 5], [4200, 2], [36139, 8], [5569, 2], [6716, 6], [49161, 6], [35127, 7], [34711, 8], [29135, 6], [11085, 3], [19846, 6], [22357, 5], [29258, 2], [12121, 7], [38276, 9], [19888, 0], [24138, 0], [28055, 8], [10643, 1], [37177, 9], [38597, 8], [7587, 8], [2235, 1], [8050, 6], [11780, 5], [43591, 3], [40994, 7], [6715, 1], [47489, 3], [43220, 3], [27810, 6], [13489, 1], [6043, 3]]\n"
     ]
    }
   ],
   "source": [
    "for c,(i,j) in enumerate(hash_dict_list[1].items()):\n",
    "    if c==15:\n",
    "        print(i,j)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash codes for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Test Batches: 100%|██████████| 157/157 [00:05<00:00, 26.84it/s]\n",
      "Processing Test Batches: 100%|██████████| 157/157 [00:05<00:00, 26.78it/s]\n",
      "Processing Test Batches: 100%|██████████| 157/157 [00:05<00:00, 27.11it/s]\n",
      "Processing Test Batches: 100%|██████████| 157/157 [00:05<00:00, 26.93it/s]\n",
      "Processing Test Batches: 100%|██████████| 157/157 [00:05<00:00, 26.68it/s]\n",
      "Processing Test Batches: 100%|██████████| 157/157 [00:06<00:00, 24.42it/s]\n",
      "Processing Test Batches: 100%|██████████| 157/157 [00:05<00:00, 27.04it/s]\n",
      "Processing Test Batches: 100%|██████████| 157/157 [00:05<00:00, 26.46it/s]\n",
      "Processing Test Batches: 100%|██████████| 157/157 [00:05<00:00, 26.98it/s]\n",
      "Processing Test Batches: 100%|██████████| 157/157 [00:05<00:00, 26.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store similar images for each hyperplane\n",
    "similar_images_list = []\n",
    "\n",
    "# Iterate through each hyperplane\n",
    "for i in range(L):\n",
    "    # Create a dictionary to store similar images for this hyperplane\n",
    "    similar_images = {}\n",
    "    random_positions = position_list[i]\n",
    "    # Process test data\n",
    "    for batch_idx, data in enumerate(tqdm(test_dataloader, desc=\"Processing Test Batches\")):\n",
    "        feature = data['features'].to(device)\n",
    "        \n",
    "\n",
    "        # Compute hash values for the test data\n",
    "        hash_value = model(feature)\n",
    "        test_hash_code = torch.where(hash_value > 0, 1, 0)\n",
    "\n",
    "        # Convert the hash code tensor to a list of tuples for dictionary key compatibility\n",
    "        test_hash_code_list = test_hash_code.tolist()\n",
    "        \n",
    "        # Iterate through each test image\n",
    "        for j in range(len(test_hash_code_list)):\n",
    "            # Create a unique key from (batch_idx, i, label)\n",
    "            test_key = (data['index'][j], data['label'][j].item())  # Convert tensor to tuple\n",
    "            test_hash_code_key = [test_hash_code_list[j][pos] for pos in random_positions]\n",
    "            # Create a unique key from the test hash code\n",
    "            test_hash_code_key = tuple(test_hash_code_key)\n",
    "\n",
    "            # Check if this hash code exists in the training hash dictionary\n",
    "            if test_hash_code_key in hash_dict_list[i]:\n",
    "                # Retrieve the corresponding images and their labels from the training hash dictionary\n",
    "                similar_images[test_key] = hash_dict_list[i][test_hash_code_key]\n",
    "            else:\n",
    "                similar_images[test_key] = []\n",
    "\n",
    "    # Store the similar images found for this hyperplane\n",
    "    similar_images_list.append(similar_images)\n",
    "\n",
    "# Now similar_images_list contains keys as (batch_idx, i, label) and values as similar images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23439, 3], [49261, 9], [25447, 1], [36372, 4], [38984, 8], [19267, 4], [38980, 5], [45887, 7], [32849, 4], [21109, 1], [45309, 2], [27850, 2], [20338, 0], [39326, 1], [38297, 8], [38097, 3], [432, 3], [33171, 9], [29840, 9], [46796, 8], [12366, 9], [43728, 3], [14811, 8], [36676, 5], [4643, 6], [35869, 4], [12376, 2], [33560, 9], [37218, 5], [41100, 3], [37293, 4], [19549, 5], [47154, 4], [45154, 0], [27019, 6], [36388, 6], [12328, 6], [45192, 3], [42280, 1], [20406, 2], [29966, 6], [17056, 8], [6793, 4], [21074, 4], [40494, 3], [11634, 0], [45410, 2], [40090, 2], [27372, 6], [16690, 3], [19937, 7], [34304, 8], [21730, 2], [10326, 3], [19427, 6], [45589, 0], [2605, 9], [23047, 2], [3170, 2], [23209, 6], [18897, 0], [15445, 5], [21086, 8], [7300, 3], [9013, 3], [1202, 8], [25257, 5], [12729, 2], [40291, 8], [28109, 3], [28356, 3], [13798, 9], [30454, 7], [44749, 9], [541, 3], [33102, 1], [24056, 0], [41278, 0], [27056, 0], [38274, 5], [40868, 4], [10194, 3], [24690, 4], [25352, 0], [20067, 4], [26526, 3], [35738, 2], [29915, 2], [6227, 5], [44546, 6], [39674, 1], [13624, 9], [11284, 2], [13117, 8], [12576, 8], [39210, 6], [33141, 9], [37352, 6], [7951, 3], [23384, 9], [23312, 0], [28400, 3], [12778, 3], [36037, 3], [1643, 9], [29011, 0], [20104, 5], [32656, 4], [6577, 9], [47494, 9], [46672, 6], [26783, 2], [25794, 3], [494, 6], [42938, 2], [1997, 2], [24391, 5], [22328, 0], [29183, 3], [17017, 4], [47368, 4], [3135, 2], [35632, 3], [39013, 4], [11449, 5], [40295, 9], [19843, 9], [12214, 8], [30871, 5], [41778, 3], [36972, 2], [35609, 4], [28257, 6], [2265, 8], [39690, 4], [26719, 7], [2334, 6], [1219, 8], [3435, 5], [37248, 2], [26287, 6], [3589, 0], [20603, 5], [15599, 0], [11945, 0], [24054, 8], [16840, 0], [21223, 1], [16331, 1], [31855, 0], [39296, 6], [37038, 5], [4361, 3], [24078, 2], [681, 4], [32559, 0], [27111, 1], [25438, 8], [8088, 6], [39559, 0], [42329, 4], [48731, 5], [45953, 8], [28713, 0], [21126, 9], [3104, 8], [15872, 1], [33526, 5], [36311, 6], [45395, 9]]\n"
     ]
    }
   ],
   "source": [
    "for i,j in similar_images_list[0].items():\n",
    "    print(j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create union of all hash list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 404773.55it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 539661.61it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 614964.52it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 778756.38it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 679988.33it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 656467.79it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 738277.83it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 742223.32it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 712009.23it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 728721.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dictionary to store similar images\n",
    "similar_images_dict = {}\n",
    "\n",
    "# Iterate through the similar_images_dict to populate similar_images_list\n",
    "for i in similar_images_list:\n",
    "    for j in tqdm(i.keys()):\n",
    "        # Check if the key already exists in similar_images_list\n",
    "        if j not in similar_images_list:\n",
    "            similar_images_dict[j] = []  # Initialize the list if it doesn't exist\n",
    "\n",
    "        similar_images_dict[j].extend(i[j])  # Deep copy of the elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:08<00:00, 1223.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dictionary to store similar images\n",
    "unique_images_dict = {}\n",
    "\n",
    "# Iterate through the similar_images_dict to populate unique_images_dict\n",
    "for i, j in tqdm(similar_images_dict.items()):\n",
    "    if i not in unique_images_dict:\n",
    "        unique_images_dict[i] = []  # Initialize the list only if the key doesn't exist\n",
    "\n",
    "    for k in j:\n",
    "        if k not in unique_images_dict[i]:  # Check if 'k' is not already in the list\n",
    "            unique_images_dict[i].append(k)  # Append 'k' to the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32417, 3], [18920, 7], [9709, 0], [14435, 8], [8503, 5], [6332, 5], [4315, 8], [8067, 7], [42321, 7], [29914, 2], [20558, 3], [37323, 7], [29332, 0], [48036, 7], [16642, 3], [42798, 8], [31412, 3], [34501, 8], [24503, 7], [44233, 8], [22671, 3], [21167, 7], [19926, 9], [49488, 8], [15042, 8], [26034, 2], [5374, 8], [1770, 2], [28916, 7], [6088, 9], [5858, 0], [18599, 8], [25369, 2], [6797, 9], [8003, 0], [3445, 2], [38844, 0], [24341, 0], [27588, 8], [32477, 8], [29785, 2], [17590, 5], [46757, 2], [25127, 3], [30645, 8], [16811, 7], [16603, 8], [6300, 2], [9092, 5], [41386, 7], [7287, 6], [15836, 7], [24162, 6], [14632, 8], [33992, 0], [45573, 8], [40796, 2], [26118, 8], [20817, 8], [24365, 0], [39837, 0], [9025, 9], [20787, 0], [40646, 2], [40303, 2], [13997, 0], [15540, 8], [28209, 9], [16243, 6], [19524, 8], [42036, 8], [16908, 9], [6438, 8], [19328, 8], [41376, 0], [25278, 3], [33795, 2], [15267, 0], [100, 6], [24846, 8], [28120, 9], [18461, 8], [44552, 0], [24132, 8], [18591, 9], [47663, 0], [7885, 5], [35073, 8], [15941, 4], [19759, 0], [29097, 8], [36604, 3], [45793, 9], [35566, 4], [31019, 0], [21553, 7], [34704, 3], [20290, 8], [6775, 7], [11040, 2], [40550, 3], [6004, 0], [39757, 8], [20965, 8], [33981, 3], [37146, 3], [6492, 2], [41836, 6], [42447, 3]]\n",
      "[[32533, 5], [39627, 7], [23677, 2], [35895, 6], [10789, 6], [6788, 6], [10042, 1], [42772, 2], [41001, 4], [9103, 5], [13950, 2], [22111, 3], [14854, 6], [16712, 1], [32596, 7], [703, 5], [40603, 3], [37685, 0], [44320, 8], [21240, 0], [7145, 1], [193, 6], [34163, 6], [4712, 8], [14162, 9], [30466, 6], [49838, 6], [8874, 5], [34092, 8], [1878, 9], [24187, 3], [22122, 6], [11818, 3], [32519, 0], [43091, 6], [35036, 7], [38606, 9], [34399, 3], [5880, 2], [22485, 5], [26677, 0], [4153, 1], [14654, 1], [20902, 1], [29539, 1], [46755, 6], [33720, 3], [25054, 2], [2278, 2], [1396, 6], [48570, 1], [32743, 2], [9163, 3], [34266, 1], [2739, 6], [16694, 8], [19841, 4], [26389, 6], [44191, 8], [13907, 8], [2399, 7], [44881, 6], [8707, 6], [42662, 0], [11956, 6], [25843, 8], [1984, 6], [19581, 2], [31635, 4], [20069, 8], [2553, 4], [6383, 4], [33212, 8], [31230, 1], [28483, 1], [17736, 9], [7820, 2], [19250, 4], [11021, 4], [8924, 5], [11039, 2], [9639, 6], [17308, 2], [40520, 4], [21066, 6], [14560, 3], [22442, 8], [44309, 6], [22180, 2], [26256, 1], [22017, 6], [1934, 3], [28645, 8], [5805, 1], [29324, 1], [244, 1], [49067, 2], [7636, 7], [39373, 0], [35923, 1]]\n",
      "[[14555, 2], [40748, 0], [19766, 8], [15241, 7], [30826, 3], [43375, 0], [21635, 4], [6780, 8], [16244, 3], [36782, 0], [38211, 4], [35285, 7], [3447, 0], [43783, 6], [32487, 4], [7793, 9], [2417, 7], [29777, 7], [17993, 3], [3057, 4], [2719, 5], [39975, 3], [46876, 7], [31240, 8], [46516, 9], [15602, 2], [38554, 0], [45947, 1], [46711, 0], [46137, 1], [14210, 2], [6883, 2], [33096, 8], [26909, 9], [24534, 0], [7195, 9], [31370, 7], [24614, 7], [6702, 6], [29159, 7], [12937, 5], [45326, 7], [13599, 7], [6935, 1], [4938, 0], [18475, 5], [9249, 4], [21130, 1], [33965, 0], [12193, 3], [4687, 5], [12980, 7], [28327, 8], [10388, 9], [38308, 9], [13284, 9], [24972, 3], [45156, 5], [37715, 9], [32636, 4], [42348, 3], [32576, 0], [39030, 4], [12468, 4], [32089, 5], [13872, 8], [23409, 7], [40798, 9], [9430, 4], [8834, 6], [48157, 2], [10799, 9], [16014, 5], [12671, 5], [2087, 1], [28900, 0], [37104, 0], [19591, 1], [40767, 5], [7086, 5], [42604, 5], [48581, 4], [47039, 8], [27519, 8], [11015, 3], [37253, 0], [10999, 8], [31467, 0], [42734, 4], [9085, 7], [40328, 8], [8229, 3], [16455, 3], [19908, 1], [17734, 3], [14222, 4], [33991, 5], [41385, 4], [28662, 3], [18306, 5], [17356, 2], [18821, 1], [39057, 9], [13669, 8], [11753, 4], [4645, 9], [46425, 0], [39796, 7], [26422, 8], [36907, 2], [10345, 3], [23865, 5], [13514, 1], [5759, 3], [47212, 0], [10021, 6], [12777, 0], [47099, 4], [29100, 9], [22208, 4], [21923, 2], [19083, 4], [18772, 3], [40223, 0], [23922, 1], [39163, 1], [35394, 7], [26561, 3], [31988, 8], [3760, 8], [21531, 3], [9733, 5], [12522, 1], [43650, 3], [30184, 1], [924, 0], [8576, 0], [11786, 9], [41655, 3], [29168, 4], [20946, 6], [48012, 9], [25824, 7], [27403, 2], [10835, 1], [29549, 9], [48401, 8], [39565, 5], [23842, 5], [18218, 5], [46957, 5], [27828, 3], [7296, 1], [23140, 6], [11242, 9], [8403, 5], [19736, 6], [31951, 3], [27121, 5], [12681, 5], [42331, 7], [20472, 4], [35046, 4], [41492, 2], [9426, 2], [25597, 9], [18971, 4], [33267, 1], [14414, 8], [2741, 2], [3970, 1], [10812, 8], [35314, 0], [30745, 4], [47948, 2], [37998, 3], [34354, 3], [8471, 5], [15321, 6], [25909, 4], [3197, 4], [23669, 9], [49930, 3], [29630, 0], [5282, 0], [19518, 0], [41784, 4], [9417, 6], [31084, 2], [19520, 3], [32984, 0], [35992, 5], [32009, 6], [7232, 2], [38450, 9], [48632, 9], [13453, 2], [33108, 9], [49150, 2], [19557, 7], [40959, 4], [22287, 2], [27115, 0], [8795, 1], [40443, 9], [15787, 0], [12676, 2], [21702, 1], [15966, 6], [16693, 0], [34128, 6], [48960, 5], [31742, 1], [5425, 8], [10658, 0], [11002, 4], [38955, 4], [21407, 1], [13906, 5], [9579, 8], [27361, 1], [43631, 6], [48016, 2], [39250, 8], [41691, 5], [7842, 7], [8816, 1], [48824, 5], [45475, 3], [39358, 8], [49792, 3], [23264, 1], [3437, 9], [22496, 5], [5474, 4], [10887, 6], [27753, 8], [26069, 6], [13174, 5], [44869, 0], [16745, 4], [21861, 5], [26674, 4], [6688, 6], [14726, 3], [31686, 1], [40038, 3], [22940, 2], [32586, 9], [17726, 7], [42846, 2], [24682, 5], [34740, 5], [43099, 9], [6005, 1], [31589, 3], [17309, 2], [41388, 4], [33936, 7], [35990, 2], [35127, 7], [49412, 9], [32494, 5], [21436, 2], [5583, 3], [44601, 0], [8565, 2], [14544, 1], [24877, 0], [26712, 2], [43156, 5], [32864, 8], [30098, 4], [26596, 0], [11499, 8], [29335, 5], [21561, 7], [1232, 6], [25532, 4], [29860, 0], [17192, 2], [32998, 0], [19748, 0], [22316, 3], [8234, 2], [17126, 6], [38803, 7], [45775, 0], [5136, 6], [32296, 4], [13740, 8], [4910, 8], [35957, 4], [11811, 6], [39902, 4], [20485, 4], [33752, 3], [45514, 4], [49285, 4], [19903, 8], [49035, 5], [6221, 8], [44139, 3], [32073, 0], [567, 5], [1747, 1], [45886, 5], [48874, 2], [15079, 7], [11678, 5], [10810, 4], [42039, 1], [34810, 9], [43509, 4], [20200, 6], [26237, 9], [29166, 1], [25625, 4], [6408, 2], [30885, 9], [2128, 3], [4332, 7], [399, 1], [5807, 9], [21583, 0], [44405, 3], [28599, 0], [24731, 9], [32698, 5], [20035, 1], [34260, 5], [2598, 5], [45650, 9], [17633, 5], [34732, 2], [21648, 7], [17269, 5], [15214, 3], [48351, 7], [17872, 6], [42439, 6], [49946, 1], [44224, 4], [10465, 3], [47898, 0], [1488, 0], [34288, 2], [24033, 5], [32240, 5], [34761, 4], [32990, 2], [34043, 8], [30990, 8], [45631, 4], [32688, 0], [34053, 2], [46176, 8], [46280, 4], [831, 5], [25935, 8], [2647, 1], [3852, 8], [42195, 7], [3958, 9], [41368, 3], [34803, 4], [7914, 5], [40865, 3], [13367, 4], [1592, 5], [17852, 4], [18479, 2], [26410, 1], [44645, 0], [21767, 1], [28411, 7], [12298, 1], [8859, 5], [20919, 8], [47177, 1], [20375, 9], [8334, 0], [16127, 1], [49189, 1], [43453, 5], [4816, 4], [29254, 8], [5216, 2], [6877, 6], [21441, 5], [21147, 6], [12748, 3], [47310, 8], [40275, 1], [22786, 3], [48239, 5], [30782, 6], [18791, 0], [3790, 9], [48164, 3], [48398, 5], [46193, 6], [30397, 4], [37706, 1], [35760, 8], [24589, 7], [43864, 3], [27850, 2], [6201, 0], [22094, 4], [25042, 1], [17297, 3], [33833, 7], [32432, 5], [3942, 8], [21981, 6], [12062, 0], [13576, 7], [6719, 9], [5888, 7], [2623, 1], [22340, 1], [6754, 9], [2072, 9], [19828, 1], [10979, 7], [24767, 8], [20748, 1], [17928, 6], [10642, 4], [13564, 1], [44653, 0], [11964, 0], [49560, 7], [37714, 5], [42257, 4], [45946, 4], [36806, 7], [11102, 2], [37534, 4], [47389, 3], [39482, 5], [19898, 6], [21129, 4], [5408, 8], [45824, 2], [28389, 3], [21641, 2], [42650, 6], [25213, 5], [41099, 9], [29563, 9], [42185, 1], [22801, 8], [15599, 0], [28233, 3], [45606, 5], [13200, 4], [21581, 7], [29457, 1], [6297, 8], [46512, 0], [11735, 7], [26762, 6], [31095, 7], [9007, 6], [14092, 3], [39552, 5], [17480, 2], [34057, 8], [45698, 5], [4033, 6], [8313, 5], [14073, 3], [7338, 5], [48604, 7], [18600, 4], [23814, 2], [37719, 2], [24390, 0], [4433, 2], [1987, 0], [27944, 7], [46886, 2], [3265, 7], [26078, 9], [26321, 5], [37817, 7], [11360, 0], [22659, 0], [14584, 4], [37840, 3], [23456, 5], [35781, 9], [7087, 0], [18361, 3], [1955, 0], [47870, 5], [9746, 9], [20895, 1], [35271, 5], [2587, 2], [1998, 4], [5291, 1], [4397, 3], [6197, 2], [27327, 8], [43394, 5], [39870, 2], [14393, 4], [9822, 3], [48236, 4], [47282, 8], [15741, 7], [44291, 9], [2444, 0], [13043, 0], [26343, 9], [46386, 7], [28808, 0], [39737, 7], [1319, 1], [31209, 1], [3707, 5], [18494, 6], [17984, 2], [33535, 5], [34226, 3], [20579, 6], [28530, 8], [16598, 3], [36457, 2], [16884, 5], [33996, 0], [7207, 8], [26381, 8], [17591, 9], [16193, 7], [29027, 0], [25218, 6], [30176, 2], [17025, 9], [41582, 7], [852, 7], [33560, 9], [25152, 4], [30854, 4], [47466, 2], [12629, 9], [13421, 4], [9087, 6], [17850, 0], [9485, 7], [6432, 9], [25128, 8], [48227, 1], [26967, 4], [24910, 7], [28342, 6], [13806, 1], [25681, 8], [9520, 2], [11316, 2], [3507, 4], [12227, 1], [14443, 3], [42374, 5], [5341, 7], [32462, 9], [40975, 2], [1048, 0], [16713, 4], [3109, 8], [2008, 9], [22547, 7], [38495, 5], [14002, 2], [21598, 8], [22422, 8], [3546, 3], [17974, 5], [49092, 8], [1361, 2], [13218, 3], [15168, 6], [34668, 0], [30428, 2], [45681, 5], [25350, 9], [28903, 6], [31305, 4], [32310, 4], [30965, 2], [29160, 5], [7218, 5], [878, 2], [12099, 5], [14641, 0], [11022, 3], [44925, 0], [25101, 9], [38419, 0], [20764, 0], [35292, 7], [10627, 5], [40472, 9], [16446, 9], [8801, 2], [22842, 7], [47116, 2], [28292, 7], [7196, 5], [12962, 0], [37235, 5], [43549, 0], [42475, 6], [29218, 2], [6388, 1], [34884, 0], [34719, 0], [28068, 9], [37108, 1], [16049, 0], [13767, 0], [49877, 6], [35902, 4], [23794, 2], [2523, 4], [28263, 1], [35830, 8], [600, 4], [25083, 3], [4117, 5], [20761, 0], [24902, 9], [44003, 8], [4526, 9], [2415, 4], [16863, 8], [24923, 4], [17381, 7], [44244, 1], [45714, 1], [20712, 7], [4786, 6], [4040, 0], [20742, 2], [6253, 8], [33649, 0], [28452, 3], [1530, 8], [20924, 5], [24082, 4], [20109, 6], [38618, 0], [44082, 6], [2228, 6], [27778, 5], [20806, 9], [24713, 1], [14606, 3], [43386, 1], [43867, 5], [11359, 6], [477, 5], [25894, 5], [40037, 7], [8190, 0], [25485, 5], [37739, 5], [44861, 0], [16460, 4], [28347, 5], [34419, 3], [39580, 9], [14077, 3], [41868, 9], [268, 4], [17113, 7], [2138, 8], [45464, 9], [22205, 5], [8430, 9], [3716, 8], [23340, 2], [39781, 2], [15158, 7], [15178, 0], [22144, 5], [29836, 8], [43717, 4], [16359, 7], [5304, 4], [38403, 5], [46081, 2], [34665, 5], [45260, 3], [19571, 1], [34135, 7], [7126, 9], [39247, 8], [34801, 7], [36783, 7], [25472, 7], [25403, 5], [16533, 7], [32017, 8], [10991, 5], [43153, 5], [47958, 6], [46283, 7], [15039, 6], [2181, 2], [9719, 0], [42883, 1], [37035, 1], [7548, 3], [12888, 8], [24974, 4], [7485, 2], [40416, 3], [15875, 5], [31657, 4], [48834, 4], [16142, 4], [5123, 6], [16283, 3], [36917, 8], [6803, 8], [17870, 8], [30960, 2], [2049, 2], [8023, 0], [1764, 7], [11718, 7], [6514, 4], [5481, 3], [6951, 3], [23391, 4], [7057, 3], [47362, 4], [41702, 8], [38507, 3], [21007, 1], [10690, 7], [1215, 7], [39991, 2], [18502, 7], [40868, 4], [13868, 9], [31220, 0], [28240, 3], [46234, 4], [32829, 0], [43499, 5], [27668, 7], [36901, 5], [5762, 5], [26514, 4], [31581, 3], [45397, 9], [10276, 4], [22593, 5], [36189, 9], [40330, 1], [18594, 2], [39876, 8], [360, 9], [16424, 1], [10029, 2], [19465, 6], [42667, 9], [7392, 9], [43236, 4], [41892, 3], [27040, 7], [8212, 7], [168, 8], [27011, 0], [48463, 5], [33338, 5], [32299, 7], [45924, 0], [31163, 8], [45078, 8], [7717, 6], [47368, 4], [1584, 3], [10644, 5], [25798, 5], [10813, 0], [49608, 9], [36419, 0], [42316, 5], [10373, 4], [24305, 4], [19858, 5], [15498, 4], [10652, 8], [5975, 7], [35402, 3], [909, 0], [40555, 0], [17549, 2], [20720, 4], [24989, 7], [20240, 2], [207, 5], [3576, 5], [23561, 0], [15092, 0], [4709, 7], [12529, 1], [28855, 2], [25489, 6], [35167, 9], [47692, 9], [15027, 0], [10900, 7], [14366, 2], [16251, 5], [49507, 4], [44087, 3], [14999, 1], [43366, 1], [13792, 4], [6757, 5], [292, 6], [26886, 5], [21743, 3], [7909, 0], [40913, 7], [12792, 7], [26536, 3], [36908, 1], [34372, 9], [38046, 4], [11271, 5], [12178, 0], [8269, 4], [48234, 2], [36633, 2], [24465, 5], [26219, 0], [48392, 0], [10229, 9], [7300, 3], [29731, 6], [28030, 9], [46179, 6], [15024, 4], [13345, 1], [14884, 4], [46730, 5], [36042, 6], [14431, 6], [72, 5], [2906, 5], [14483, 9], [15541, 3], [21189, 5], [12631, 6], [38127, 8], [34486, 6], [29460, 4], [16976, 2], [25697, 2], [8502, 2], [42072, 1], [41787, 2], [17077, 3], [32763, 8], [47774, 1], [25242, 5], [33660, 0], [27574, 6], [28478, 5], [37866, 3], [35474, 6], [36057, 5], [1746, 7], [38132, 3], [17745, 1], [33052, 3], [44573, 4], [15848, 7], [48772, 4], [3428, 3], [16377, 5], [8413, 8], [4587, 9], [27844, 2], [11867, 2], [2272, 5], [39422, 5], [49790, 2], [28812, 8], [19094, 9], [10889, 8], [13714, 1], [34356, 7], [44600, 5], [34325, 5], [38579, 7], [31340, 5], [35837, 2], [2500, 6], [43086, 9], [18862, 2], [44020, 3], [37717, 3], [33400, 8], [23615, 1], [48292, 0], [29620, 9], [36051, 1], [12189, 0], [3205, 2], [48469, 7], [35968, 1], [41179, 7], [20082, 5], [22868, 8], [36465, 7], [13384, 8], [34795, 6], [41140, 9], [10712, 2], [1610, 3], [17991, 5], [30120, 7], [2818, 4], [30544, 6], [16008, 1], [11630, 2], [4665, 9], [28213, 9], [24750, 5], [11019, 6], [37605, 4], [15747, 6], [1247, 7], [16192, 6], [17531, 4], [34118, 5], [38711, 5], [45300, 9], [6275, 3], [12157, 6], [77, 4], [37044, 3]]\n",
      "[[41233, 9], [21211, 3], [33509, 4], [11536, 3], [11555, 9], [5309, 2], [47676, 4], [44690, 9], [8655, 2], [21317, 5], [44719, 2], [25975, 2], [47296, 4], [2978, 5], [26177, 6], [49916, 2], [25747, 5], [29048, 9], [30485, 0], [20640, 4], [5847, 1], [35675, 1], [25416, 8], [7108, 5], [31991, 2], [34509, 7], [31830, 6], [32307, 1], [47608, 9], [48121, 2], [48077, 2], [44090, 2], [2796, 5], [42793, 9], [42854, 2], [42318, 1], [29830, 3], [16146, 2], [24255, 4], [6276, 4], [2006, 3], [38622, 9], [20078, 9], [41283, 2], [38693, 5], [31930, 2], [14573, 7], [21838, 0], [37498, 2], [16177, 0], [35252, 2], [45321, 3], [43469, 8], [1107, 1], [2892, 4], [24099, 9], [1395, 1], [8976, 3], [7803, 8], [28907, 1], [24157, 2], [34846, 4], [31004, 6], [44747, 7], [7265, 0], [5161, 2], [7962, 0], [30165, 3], [46626, 2], [45859, 3], [45493, 3], [32769, 4], [33376, 9], [19000, 9], [15659, 0]]\n",
      "[[35395, 3], [766, 5], [7252, 5], [36104, 9], [38071, 0], [33929, 7], [19471, 4], [48493, 9], [3644, 2], [49568, 4], [47556, 9], [28594, 1], [17175, 0], [46812, 3], [9238, 9], [9473, 4], [1598, 6], [5994, 3], [19977, 0], [8278, 1], [16568, 2], [10578, 9], [18700, 3], [24430, 7], [44431, 2], [17164, 6], [29506, 5], [42630, 1], [38051, 9], [23549, 0], [32045, 2], [30651, 3], [49549, 1], [20861, 4], [33877, 3], [12475, 9], [44850, 5], [18964, 3], [10594, 8], [12004, 6], [7041, 0], [42376, 3], [14822, 5], [14600, 0], [47288, 1], [15545, 3], [21779, 2], [11739, 3], [40188, 9], [32851, 9], [11309, 1], [977, 0], [5411, 0], [24196, 7], [25159, 9], [36272, 8], [23037, 1], [30787, 2], [10567, 7], [15657, 6], [36184, 7], [47747, 0], [39490, 0], [6612, 7], [48279, 4], [15589, 5], [25720, 7], [6355, 2], [7583, 8], [32101, 9], [10011, 4], [3074, 7], [32355, 7], [859, 8], [13426, 9], [11581, 6], [26780, 3], [46144, 4], [24392, 6], [326, 4], [49730, 8], [12127, 9], [37320, 0], [29073, 9], [29947, 1], [39626, 3], [37630, 4], [43488, 2], [314, 1], [6261, 2], [1106, 9], [20135, 3], [12398, 7], [35039, 6], [42016, 9], [7971, 7], [13964, 0], [28282, 6], [48148, 2], [12983, 1], [49806, 1], [33669, 1], [10287, 0], [40632, 4], [44429, 4], [49808, 6], [24862, 7], [46103, 4], [14147, 3], [45354, 3], [932, 9], [27008, 1], [48386, 3], [24795, 1], [46485, 4], [1629, 6], [47618, 7], [27305, 5], [12367, 9], [40237, 7], [37502, 3], [38909, 3], [321, 0], [4779, 3], [49211, 9], [29348, 7], [49748, 5], [40410, 8], [48649, 3], [9909, 6], [8309, 6], [40821, 7], [29995, 8], [45882, 6], [36303, 0], [39983, 3], [49920, 0], [34957, 3], [17576, 1], [16032, 7], [30921, 6], [5386, 5], [34516, 4], [49855, 6], [39187, 4], [34125, 4], [37247, 9], [26433, 4], [23049, 6], [31080, 2], [35304, 0], [11940, 2], [25544, 5], [34858, 7], [36537, 9], [33105, 3], [31727, 8], [9423, 3], [39128, 0], [18215, 9], [6605, 3], [43004, 6], [32125, 7], [16750, 2], [16558, 3], [40972, 7], [32241, 0], [3357, 4], [21261, 8], [42193, 2], [14229, 0], [47374, 1], [36281, 1], [39937, 1], [23622, 7], [11256, 3], [14920, 4], [27885, 9], [4759, 8], [36775, 9], [44609, 1], [43092, 0], [12604, 0], [23084, 0], [5582, 3], [16988, 8], [38466, 7], [8765, 2], [42128, 8], [11948, 3], [44032, 4], [9491, 4], [43746, 5], [22831, 6], [16289, 9], [45371, 0], [47580, 8], [18911, 7], [43170, 8], [4238, 1], [11908, 6], [41589, 0], [39303, 0], [34513, 3], [34766, 2], [40682, 6], [35058, 7], [4396, 2], [40381, 4], [41165, 7], [29327, 3], [44417, 6], [25820, 2], [40356, 2], [8035, 9], [46072, 7], [42953, 9], [39950, 4], [21518, 2], [34703, 4], [9152, 3], [32693, 8], [11221, 9], [37410, 3], [23335, 6], [13683, 6], [21056, 0], [24720, 2], [20757, 6], [47152, 7], [19880, 0], [46219, 8], [21839, 4], [14232, 6], [24468, 0], [35795, 2], [36962, 3], [37499, 6], [45733, 3], [49031, 0], [2377, 2], [43133, 4], [6642, 6], [16050, 9], [33579, 7], [3364, 6], [44174, 3], [29846, 4], [12578, 8], [43257, 1], [31528, 6], [20595, 3], [30001, 8], [19196, 7], [18247, 5], [42990, 4], [12691, 2], [30868, 5], [10941, 2], [22955, 9], [29761, 0], [40592, 8], [5797, 4], [3295, 5], [9168, 7], [46456, 1], [1744, 9], [42213, 4], [35384, 0], [15851, 6], [23733, 3], [31057, 3], [24391, 5], [5899, 3], [41048, 3], [33135, 2], [135, 1], [697, 9], [26868, 7], [38081, 8], [18561, 4], [6417, 7], [25302, 9], [3919, 0], [22934, 6], [13214, 8], [33483, 0], [38722, 3], [3326, 9], [4210, 8], [40833, 1], [913, 0], [20545, 0], [13015, 1], [35375, 8], [26879, 7], [28266, 8], [1556, 0], [41816, 0], [5702, 9], [40432, 1], [19257, 0], [41243, 0], [31925, 2], [35197, 9], [21990, 7], [19366, 4], [8825, 3], [29076, 9], [4682, 3], [17533, 0], [10533, 2], [42043, 6], [44592, 0], [42156, 0], [26916, 6], [29780, 3], [46288, 9], [44633, 2], [33337, 4], [11334, 9], [25404, 2], [35427, 1], [6659, 9], [13448, 5], [3750, 0], [26703, 3], [6471, 5], [41880, 4], [48711, 3], [11076, 2], [21180, 8], [22367, 6], [36959, 9], [33586, 4], [30170, 6], [4288, 6], [7766, 2], [48659, 7], [35276, 7], [27940, 6], [1513, 7], [21740, 5], [24156, 2], [38000, 1], [1132, 5], [26274, 2], [5470, 0], [29373, 2], [18315, 4], [10131, 3], [48571, 1], [49002, 2], [48160, 0], [1523, 1], [41670, 2], [43680, 8], [14747, 2], [34785, 0], [28453, 9], [29895, 3], [2659, 0], [18340, 5], [41475, 2], [12200, 0], [32874, 7], [20084, 7], [8992, 3], [12470, 5], [8354, 4], [29140, 3], [32964, 7], [2666, 9], [9374, 3], [16230, 1], [38190, 6], [20525, 4], [39268, 2], [48000, 3], [26498, 2], [3135, 2], [1347, 5], [45455, 3], [43314, 4], [11074, 0], [1316, 7], [15862, 0], [17720, 5], [44033, 3], [28910, 6], [46356, 1], [7600, 9], [32238, 7], [14880, 9], [33616, 9], [15976, 0], [32930, 3], [22194, 8], [3334, 4], [38084, 9], [34117, 1], [4841, 5], [32137, 7], [42113, 7], [19684, 3], [12731, 5], [28219, 7], [8968, 6], [47709, 1], [1129, 5], [43829, 8], [28433, 6], [11069, 7], [41294, 4], [26701, 5], [15648, 9], [15897, 9], [2510, 3], [47966, 8], [48686, 3], [13910, 7], [39119, 6], [44441, 7], [14846, 4], [46906, 9], [45528, 8], [8289, 0], [16473, 5], [26025, 7], [48428, 9], [45691, 9], [44143, 6], [15490, 3], [30013, 1], [9367, 8], [9670, 0], [23923, 8], [40626, 0], [14498, 4], [8956, 3], [41960, 0], [43145, 4], [42998, 6], [38845, 1], [9235, 3], [33116, 2], [5735, 5], [15394, 5], [17721, 2], [133, 5], [13761, 3], [24811, 2], [29156, 5], [246, 2], [38232, 2], [35812, 4], [26654, 7], [38967, 5], [21381, 6], [4368, 6], [23578, 0], [33497, 3], [45956, 0], [24310, 4], [7744, 7], [46745, 6], [39024, 4], [36220, 4], [34296, 0], [47132, 3], [7520, 7], [17972, 9], [44006, 1], [14607, 1], [48607, 1], [10298, 8], [10462, 9], [1937, 9], [32619, 6], [11713, 9], [17125, 5], [32106, 9], [41710, 3], [34571, 1], [6000, 3], [22494, 1], [44392, 3], [22086, 9], [22649, 5], [6898, 9], [43267, 9], [34558, 4], [22722, 7], [29775, 8], [13459, 5], [48047, 4], [25976, 9], [40976, 4], [19941, 0], [39886, 1], [10759, 0], [32145, 6], [14230, 4], [657, 5], [10849, 3], [48262, 3], [40131, 7], [46495, 1], [15563, 3], [35114, 4], [43749, 3], [7191, 0], [48861, 8], [30622, 9], [26799, 5], [14704, 3], [1229, 2], [27779, 2], [17168, 9], [34127, 3], [4014, 3], [739, 6], [17212, 3], [26808, 3], [31252, 4], [8246, 3], [46410, 4], [23117, 6], [6741, 9], [5935, 3], [20912, 1], [49132, 5], [11299, 3], [24868, 9], [29822, 4], [37723, 8], [39537, 6], [40258, 3], [27565, 3], [38368, 3], [18045, 1], [40533, 2], [12030, 3], [15645, 6], [12039, 6], [17711, 5], [22268, 8], [26971, 3], [39692, 3], [39481, 3], [25069, 1], [29831, 9], [12575, 4], [3030, 2], [39676, 1], [5054, 4], [36244, 2], [8149, 3], [3726, 6], [1275, 2], [6740, 4], [28688, 7], [18991, 3], [20758, 5], [28721, 5], [23216, 6], [21480, 3], [21354, 2], [22620, 1], [7897, 7], [13375, 6], [40838, 6], [1875, 5], [15296, 2], [20140, 7], [32778, 6], [43564, 0], [36118, 2], [45537, 2], [11916, 5], [48667, 1], [4820, 6], [5838, 6], [25364, 7], [18098, 1], [34783, 2], [45761, 7], [16458, 9], [46547, 2], [36231, 3], [45270, 5], [21807, 4], [48596, 7], [24336, 1], [39389, 8], [28355, 9], [39833, 9], [8839, 5], [9506, 3], [24056, 0], [46222, 5], [7331, 5], [11387, 0], [2614, 3], [48787, 8], [39013, 4], [1416, 6], [11166, 0], [12060, 1], [23903, 4], [48565, 9], [47571, 9], [24624, 8], [49633, 4], [22304, 3], [40422, 7], [31695, 1], [26865, 4], [10248, 9], [18390, 9], [29468, 3], [43639, 2], [15738, 3], [17616, 9], [30232, 3], [23096, 9], [3382, 7], [44060, 0], [13014, 2], [10474, 0], [39304, 5], [43268, 8], [28696, 1], [9545, 8], [35013, 1], [45616, 1], [39872, 3], [41619, 9], [37698, 2], [43847, 2], [49127, 1], [43222, 3], [9537, 6], [18002, 4], [48018, 0], [13292, 7], [23062, 3], [983, 3], [14196, 5], [43449, 8], [7551, 1], [3817, 8], [42149, 1], [24216, 0], [10418, 3], [19035, 7], [4666, 9], [12371, 4], [39548, 5], [49987, 5], [44966, 6], [20478, 4], [48714, 3], [7124, 4], [17300, 5], [5712, 5], [19664, 7], [35193, 2], [45277, 3], [18415, 9], [47451, 8], [30104, 0], [12901, 7], [42189, 0], [16719, 6], [18655, 1], [40777, 8], [39801, 7], [17877, 2], [12292, 1], [9583, 9], [23650, 0], [1467, 2], [20380, 1], [41696, 3], [39290, 2], [41158, 4], [7409, 2], [24544, 6], [13574, 4], [38004, 5], [42627, 3], [49125, 6], [19231, 1], [33034, 3], [37702, 3], [18827, 2], [3379, 2], [6592, 7], [45559, 1], [35706, 8], [24016, 9], [5760, 4], [7433, 9], [28251, 4], [18534, 9], [36903, 5], [46930, 3], [43815, 0], [14027, 9], [15081, 3], [31217, 1], [28836, 4], [4539, 6], [2352, 5], [21088, 7], [47235, 3], [7640, 3], [47846, 5], [6423, 2], [2830, 0], [43761, 4], [28898, 9], [32824, 9], [2610, 7], [2271, 8], [28685, 5], [6150, 5], [12514, 8], [7000, 7], [6807, 9], [4430, 6], [39308, 0], [13844, 7], [28184, 2], [2890, 4], [5971, 6], [32255, 7], [17598, 5], [30097, 3], [34119, 5], [151, 4], [47143, 6], [9108, 3], [5083, 3], [44894, 7], [20142, 8], [1600, 0], [26056, 0], [34548, 9], [37537, 9], [37556, 7], [8705, 2], [26383, 4], [1029, 0], [22817, 0], [30230, 7], [27288, 4], [4762, 6], [375, 5], [22574, 2], [21848, 7], [44490, 0], [11793, 9], [16958, 5], [7018, 4], [16154, 3], [18484, 5], [25383, 3], [7130, 0], [37355, 0], [35999, 7], [10725, 1], [48270, 8], [48972, 8], [7779, 1], [40157, 5], [46131, 5], [26529, 0], [33740, 0], [38716, 4]]\n",
      "[[32131, 3], [1370, 8], [26359, 9], [3006, 5], [59, 3], [28225, 2], [18864, 3], [27771, 1], [45042, 4], [6445, 1], [24180, 2], [2579, 7], [12400, 8], [6521, 9], [16388, 5], [47642, 4], [40278, 9], [2293, 3], [6865, 9], [29638, 7], [4754, 6], [12855, 3], [25693, 9], [45744, 3], [31024, 2], [17779, 3], [18148, 1], [33970, 2], [34934, 5], [4620, 2], [17581, 9], [23670, 9], [39809, 7], [41674, 0], [28582, 3], [40106, 8], [49846, 3], [15910, 1], [36726, 7], [11686, 3], [29459, 5], [13305, 9], [35712, 4], [33156, 5], [10173, 4], [5267, 2], [3131, 3], [46486, 6], [36443, 3], [16913, 0], [45677, 4], [20775, 8], [21470, 1], [32336, 3], [12467, 3], [25701, 5], [1683, 4], [12042, 3], [11560, 6], [2536, 6], [704, 3], [49123, 0], [21431, 0], [4974, 2], [2595, 9], [43941, 9], [16114, 4], [33011, 5], [42191, 2], [6055, 0], [11801, 9], [988, 2], [13594, 3], [39285, 6], [16219, 2], [9282, 5], [20362, 1], [13987, 6], [25740, 1], [34678, 9], [40645, 6], [32050, 8], [27950, 1], [3501, 4], [33517, 4], [8660, 4], [48391, 7], [34920, 9], [26872, 3], [29341, 1], [10299, 7], [27246, 8], [37131, 3], [41686, 8], [38784, 2], [46177, 2], [22291, 1], [1295, 3], [32880, 3], [16136, 9], [38725, 8], [25845, 5], [9973, 5], [29774, 4], [49191, 2], [25654, 2], [21372, 0], [21976, 3], [14551, 3], [16754, 4], [17942, 1], [47549, 6], [42730, 5], [5552, 5], [1008, 9], [21802, 0], [10226, 2], [44728, 5], [37528, 5], [44290, 4], [34529, 1], [43107, 5], [19236, 7], [38619, 6], [13038, 2], [19066, 1], [46109, 1], [7629, 9], [21293, 3], [20148, 0], [17489, 4], [32072, 4], [45169, 6], [30384, 3], [32530, 5], [36131, 9], [46997, 9], [17580, 2], [3879, 3], [39842, 9], [20529, 7], [43857, 8], [21455, 2], [49355, 5], [49634, 5], [10077, 2], [17033, 8], [16245, 6], [44274, 8], [40882, 3], [353, 4], [29534, 9], [11454, 4], [49326, 8], [39566, 1], [21903, 6], [41658, 3], [37457, 1], [31766, 4], [21125, 4], [17892, 5], [14921, 6], [48165, 2], [32976, 1], [14233, 7], [31260, 6], [31302, 4], [41660, 1], [16882, 4], [37613, 4], [6802, 8], [4511, 7], [44988, 8], [25066, 9], [38259, 2], [49499, 0], [28143, 2], [29212, 7], [3118, 1], [40793, 8], [41169, 4], [13377, 0], [17146, 9], [46922, 1], [6465, 2], [38671, 0], [914, 0], [25696, 2], [6070, 2], [7173, 3], [30567, 7], [1676, 3], [24421, 2], [21997, 4], [40437, 6], [7639, 4], [25869, 2], [5990, 1], [35409, 7], [18106, 6], [25668, 4], [16827, 5], [34723, 9], [41697, 9], [28004, 5], [25968, 5], [23154, 2], [39514, 5], [19767, 6], [37413, 3], [12973, 0], [14780, 2], [8952, 8], [10685, 3], [7219, 6], [4881, 4], [11046, 5], [20310, 3], [4571, 1], [14041, 1], [379, 9], [6334, 1], [41528, 3], [24259, 5], [20706, 4], [42487, 8], [36113, 0], [9149, 0], [13497, 8], [46843, 2], [4683, 8], [15572, 7], [5429, 4], [8543, 4], [21609, 6], [14909, 5], [10413, 3], [24765, 9], [41420, 6], [39370, 9], [25925, 4], [15903, 5], [47377, 0], [43896, 5], [24482, 0], [30167, 4], [39964, 5], [44301, 4], [17498, 2], [49489, 3], [43802, 4], [5272, 3], [40670, 5], [20575, 3], [3860, 7], [46967, 1], [35481, 5], [18729, 4], [11787, 7], [3837, 5], [23266, 8], [46624, 7], [11377, 8], [29085, 7], [40270, 9], [19441, 7], [44568, 6], [38027, 6], [13374, 8], [1940, 3], [41314, 8], [40451, 6], [8404, 4], [41210, 6], [34428, 6], [22203, 6], [33780, 9], [8999, 3], [5785, 2], [43037, 2], [28791, 7], [35300, 6], [10800, 6], [42271, 5], [35578, 8], [25131, 4], [34079, 4], [6582, 6], [34424, 7], [23931, 3], [13533, 1], [3026, 7], [6343, 1], [45870, 3], [3403, 2], [35949, 3], [41422, 9], [8518, 0], [45554, 2], [31884, 2], [35756, 4], [1493, 2], [17087, 6], [27518, 5], [26363, 3], [12799, 0], [38742, 3], [22665, 4], [25165, 6], [25595, 3], [48313, 0], [49625, 6], [44311, 0], [46533, 5], [47381, 1], [37314, 1], [46946, 2], [9967, 5], [11082, 7], [13857, 3], [16469, 6], [32985, 4], [9076, 0], [34254, 4], [28396, 6], [36904, 1], [5391, 0], [22969, 3], [35086, 9], [5293, 3], [201, 5], [9243, 8], [30153, 6], [28010, 7], [45016, 2], [31183, 9], [2497, 6], [38075, 1], [31137, 3], [36935, 0], [38664, 6], [49028, 9], [46545, 6], [43767, 5], [22029, 0], [30882, 6], [42101, 1], [691, 8], [31117, 3], [44424, 5], [48208, 4], [38376, 3], [37395, 8], [3415, 1], [49677, 5], [30007, 3], [44676, 7], [38154, 6], [30370, 3], [26979, 5], [19986, 1], [25171, 9], [4082, 4], [15165, 1], [35981, 4], [42702, 2], [34922, 7], [27789, 8], [17865, 2], [28400, 3], [45899, 5], [28331, 1], [48666, 8], [43205, 2], [33053, 5], [37855, 4], [9986, 6], [30482, 0], [27428, 9], [20257, 9], [43359, 8], [27902, 2], [34404, 9], [8050, 6], [39673, 7], [452, 3], [6540, 5], [11871, 1], [23554, 6], [26159, 8], [23532, 5], [17869, 5], [49680, 4], [44484, 3], [5724, 7], [13343, 2], [42038, 1], [3107, 2], [44415, 6], [29303, 6], [7733, 3], [27619, 5], [7180, 3], [7622, 5], [9276, 7], [23305, 8], [36160, 3], [44630, 3], [132, 4], [34171, 4], [42278, 7], [49183, 3], [43563, 6], [40247, 4], [7580, 9], [38220, 5], [24332, 9], [15768, 4], [47035, 4], [37014, 3], [9925, 2], [42145, 0], [15142, 4], [22791, 5], [21734, 0], [13694, 5], [19221, 9], [23937, 0], [42133, 2], [1188, 8], [7201, 9], [16152, 9], [26395, 8], [35464, 9], [27391, 3], [39840, 3], [45917, 1], [24159, 5], [27573, 0], [29668, 1], [43972, 8], [29132, 8], [12176, 6], [1005, 2], [829, 0], [39212, 6], [45818, 2], [2944, 5], [31535, 9], [33341, 9], [24961, 5], [28797, 8], [1495, 2], [44435, 3], [48867, 6], [42224, 2], [21283, 0], [27974, 9], [24613, 8], [21725, 5], [14224, 1], [37305, 4], [30118, 1], [28271, 0], [49496, 7], [26539, 6], [29151, 3], [42460, 0], [11047, 6], [46148, 6], [36394, 0], [20996, 9], [38531, 2], [9003, 4], [19376, 4], [357, 8], [14617, 2], [3571, 8], [33914, 4], [49667, 3], [15652, 1], [6142, 4], [23691, 4], [20269, 7], [34705, 4], [46509, 4], [27727, 4], [38293, 1], [34313, 3], [7843, 0], [43190, 3], [12634, 3], [3975, 0], [41448, 1], [12387, 5], [5334, 5], [6621, 0], [9366, 3], [15839, 9], [38535, 5], [22445, 6], [17171, 8], [31712, 8], [20664, 8], [49337, 5], [762, 8], [28455, 4], [26174, 9], [25888, 2], [26832, 8], [25657, 6], [37284, 3], [39623, 6], [33605, 1], [27183, 0], [12974, 2], [15063, 1], [8639, 0], [45583, 6], [39210, 6], [33035, 8], [41984, 4], [4771, 3], [19696, 6], [6967, 9], [38760, 4], [41238, 4], [10003, 6], [13251, 6], [22184, 5], [6560, 8], [45457, 0], [40962, 1], [41786, 5], [4554, 1], [46544, 1], [48453, 0], [11438, 6], [2102, 9], [41278, 0], [42287, 0], [6875, 9], [24770, 2], [15661, 5], [24306, 8], [42414, 3], [2324, 5], [8609, 3], [49647, 3], [35017, 8], [49228, 3], [43892, 6], [14936, 1], [576, 6], [29242, 1], [8750, 2], [29845, 2], [33804, 1], [34617, 7], [22182, 9], [43760, 2], [23122, 1], [32993, 2], [25947, 4], [39464, 6], [11201, 4], [15196, 1], [27369, 3], [6516, 2], [32452, 9], [12690, 0], [34532, 5], [25032, 5], [42056, 4], [13917, 6], [23435, 2], [26766, 1], [44140, 8], [25533, 4], [29094, 0], [1454, 2], [27527, 5], [29106, 0], [20789, 7], [4249, 1], [39366, 3], [33074, 6], [19064, 7], [21120, 3], [39129, 6], [8861, 2], [3921, 7], [45968, 9], [9486, 0], [31085, 2], [17651, 6], [1240, 5], [25836, 3], [20656, 0], [21365, 5], [21404, 6], [39542, 8], [43100, 3], [30831, 5], [38159, 4], [8811, 3], [22708, 9], [2775, 0], [12049, 3], [13722, 9], [47542, 2], [6989, 4], [45550, 2], [18828, 0], [21880, 5], [25356, 2], [38448, 6], [38366, 2], [21311, 9], [5694, 1], [21824, 1], [14189, 3], [49902, 9], [24528, 0], [13854, 0], [7716, 7], [11563, 1], [39015, 3], [7565, 8], [30016, 6], [15120, 9], [14513, 4], [10598, 8], [44897, 8], [41066, 5], [37592, 9], [41749, 8], [25890, 2], [49261, 9], [27539, 1], [15583, 5], [22913, 5], [47008, 2], [35428, 2], [30671, 8], [1214, 0], [9127, 4], [10509, 8], [36320, 6], [32811, 4], [30364, 6], [33527, 2], [30451, 9], [15721, 8], [48230, 5], [3206, 1], [43663, 2], [22939, 6], [10773, 7], [36188, 6], [8850, 8], [24366, 5], [12402, 3], [19570, 2], [17583, 7], [20770, 3], [16737, 1], [28123, 1], [45834, 1], [28324, 3], [26095, 7], [38182, 1], [30244, 2], [27604, 6], [33424, 6], [11545, 8], [24105, 4], [18288, 1], [41659, 4], [2770, 5], [36887, 2], [36594, 3], [15279, 1], [9164, 7], [7216, 5], [2461, 8], [31733, 1], [12130, 7], [48965, 1], [35010, 0], [40895, 3], [9885, 3], [33753, 5], [31248, 1], [46822, 7], [40473, 6], [48281, 9], [36830, 9], [39351, 6], [26723, 1], [12242, 6], [22560, 1], [40630, 2], [43511, 2], [46314, 4], [13951, 2], [44673, 0], [10707, 7], [3355, 3], [23188, 6], [19800, 7], [43027, 4], [18831, 5], [35381, 4], [46096, 6], [38985, 4], [44865, 9], [34023, 6], [31177, 6], [18854, 5], [47438, 1], [41976, 5], [46695, 7], [6495, 7], [3694, 0], [46645, 6], [29207, 2], [14603, 9], [15922, 3], [19102, 4], [12540, 0], [30017, 2], [43540, 4], [22871, 2], [48452, 5], [8030, 2], [14369, 4], [28531, 3], [1030, 4], [20719, 4], [33117, 6], [46690, 3], [35980, 2], [4524, 5], [7013, 6], [28643, 5], [46347, 1], [48980, 7], [14615, 9], [3578, 5], [930, 0], [36947, 4], [42174, 3], [19373, 5], [8040, 3], [13080, 8], [27692, 0], [5813, 9], [26179, 4], [4175, 9], [398, 8], [9628, 0], [47874, 7], [29486, 9], [27923, 8], [30517, 7], [41088, 5], [9062, 2], [14680, 1], [47698, 9], [31076, 7], [46343, 3], [36582, 8], [47886, 8], [47137, 6], [9308, 2], [23845, 1], [12802, 9], [24061, 1], [26698, 5], [7399, 3], [43935, 1], [26347, 9], [44734, 6], [29861, 5], [19404, 4], [1622, 6], [46362, 2], [2582, 2], [47797, 2], [25151, 1], [43017, 5], [11752, 1], [23479, 6], [24095, 7], [4398, 2], [7079, 0], [28750, 9], [47689, 3], [41196, 3], [41330, 5], [27613, 4], [20271, 1], [39582, 3], [79, 4], [38325, 6], [2688, 7], [8549, 1], [17000, 0], [2774, 3], [26988, 8], [5662, 0], [22380, 2], [16189, 3], [17662, 3], [27156, 0], [40852, 5], [25158, 4], [3367, 6], [11086, 7], [25123, 9], [34565, 4], [5704, 3], [850, 9], [29456, 6], [42926, 4], [11794, 4], [15318, 0], [8506, 8], [6047, 4], [17907, 9], [11535, 7], [16503, 5], [7647, 2], [19854, 0], [33414, 6], [2914, 3], [5775, 5], [25183, 1], [33004, 6], [1612, 4], [13811, 7], [2186, 4], [47010, 9], [49204, 4], [16528, 8], [39170, 3], [23976, 3], [38849, 3], [8720, 4], [25565, 2], [39618, 3], [40327, 6], [47591, 6], [4623, 3], [31184, 6], [1509, 9], [12726, 2], [39133, 7], [12741, 7], [31381, 7], [45261, 1], [11066, 4], [7127, 2], [33523, 2], [22768, 5], [3762, 1], [45056, 9], [5366, 1], [6156, 4], [17622, 9], [18337, 9], [39680, 5], [27490, 0], [43636, 6], [19336, 0], [3108, 2], [6960, 4], [21041, 6], [29765, 1], [39143, 3], [35321, 5], [16659, 9], [32721, 5], [48359, 0], [34832, 5], [33120, 5], [15849, 5], [1441, 9], [17625, 1], [57, 6], [37781, 5], [42372, 2], [31592, 9], [278, 7], [39778, 8], [6132, 5], [31509, 8], [28539, 9], [30150, 0], [14796, 5], [42071, 5], [33351, 4], [48204, 5], [10171, 5], [26485, 4], [17100, 4], [32594, 2], [25317, 7], [40091, 3], [10625, 3], [25304, 0], [38101, 2], [13121, 5], [40620, 6], [42054, 5], [17433, 3], [19079, 2], [18792, 3], [5924, 7], [10280, 4], [41526, 4], [46942, 8], [5865, 7], [7584, 3], [27376, 5], [45914, 3], [26489, 6], [17237, 9], [40816, 4], [400, 0], [6981, 0], [23889, 9], [41571, 1], [37417, 7], [456, 5], [12796, 0], [9086, 6], [24993, 3], [43928, 9], [7762, 9], [41899, 7], [8959, 6], [1463, 3], [10552, 9], [9398, 3], [21608, 7], [26339, 3], [14463, 1], [8964, 4], [49605, 5], [23434, 0], [12281, 2], [2393, 5], [28280, 5], [1288, 1], [17588, 9], [49784, 6], [19709, 2], [11480, 4], [41874, 6], [41104, 3], [29853, 3], [32866, 5], [48315, 7], [11128, 5], [45976, 7], [36179, 2], [21182, 6], [5711, 2], [5376, 7], [36226, 3], [27765, 9], [14313, 2], [16666, 8], [45614, 0], [5728, 1], [4220, 5], [28211, 0], [42235, 4], [17114, 3], [43128, 0], [23786, 2], [30151, 5], [47911, 6]]\n"
     ]
    }
   ],
   "source": [
    "for k,(i,j) in enumerate(unique_images_dict.items()):\n",
    "    print(j)\n",
    "    if k==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing keys: 100%|██████████| 10000/10000 [12:16<00:00, 13.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process each key in similar_images_dict with tqdm\n",
    "for key, similar_images in tqdm(unique_images_dict.items(), desc=\"Processing keys\"):\n",
    "    \n",
    "    test_feature = torch.tensor(ds_feature['test'][key[0]]['features'])\n",
    "    # Process each similar image for the current key with tqdm\n",
    "    for i, image in tqdm(enumerate(similar_images), desc=f\"Processing similar images for key {key[0]}\", leave=False):\n",
    "        # Assuming image is a list/tuple with at least four elements\n",
    "        train_feature = torch.tensor(ds_feature['train'][image[0]]['features'])\n",
    "        \n",
    "        # Calculate cosine similarity and store it\n",
    "        similarity_score = F.cosine_similarity(test_feature, train_feature, dim=0)\n",
    "        image = list(image[:2])  # Make a copy to modify\n",
    "        # Append the similarity score to the copied list\n",
    "        image.append(similarity_score.item())\n",
    "        \n",
    "        # Update the original list in similar_images\n",
    "        similar_images[i] = image[:3]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_images_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating metrics: 10000it [00:01, 6623.11it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision (mAP): 0.7755063350586736\n",
      "Precision@10: 0.6174917491749176\n",
      "Precision@50: 0.3157375737573757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define functions to calculate Average Precision (AP) and Precision@K\n",
    "def average_precision(predictions, targets):\n",
    "    relevant_indices = (targets == 1).nonzero(as_tuple=True)[0]\n",
    "    if len(relevant_indices) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    precisions = []\n",
    "    for i, idx in enumerate(relevant_indices, start=1):\n",
    "        precision_at_i = (targets[:idx + 1].sum() / (idx + 1)).item()\n",
    "        precisions.append(precision_at_i)\n",
    "\n",
    "    return sum(precisions) / len(precisions)\n",
    "\n",
    "def precision_at_k(predictions, targets, k):\n",
    "    top_k_indices = torch.argsort(predictions, descending=True)[:k]\n",
    "    top_k_relevant = targets[top_k_indices].sum().item()\n",
    "    return top_k_relevant / k\n",
    "\n",
    "# Prepare lists to store metric scores\n",
    "map_scores = []\n",
    "precision_10_scores = []\n",
    "precision_50_scores = []\n",
    "\n",
    "# Example: Iterate over your dataset to calculate metrics\n",
    "for key, value in tqdm(unique_images_dict.items(), desc=\"Calculating metrics\", total=len(similar_images_list)):\n",
    "    if len(value) > 0:\n",
    "        # Sort the values by similarity score (assuming v[4] is the similarity score)\n",
    "        sorted_value = sorted(value, key=lambda x: x[-1], reverse=True)[:50]\n",
    "        predictions = torch.tensor([v[2] for v in sorted_value])  # Similarity scores\n",
    "        targets = torch.tensor([v[1] == key[1] for v in sorted_value], dtype=torch.float32)  # Relevance labels\n",
    "        \n",
    "        # Calculate Mean Average Precision for the current sample\n",
    "        ap = average_precision(predictions, targets)\n",
    "        map_scores.append(ap)\n",
    "        \n",
    "        # Calculate Precision@10 and Precision@50\n",
    "        p10 = precision_at_k(predictions, targets, k=10)\n",
    "        p50 = precision_at_k(predictions, targets, k=50)\n",
    "        precision_10_scores.append(p10)\n",
    "        precision_50_scores.append(p50)\n",
    "\n",
    "# Calculate final average metrics\n",
    "mean_avg_precision = sum(map_scores) / len(map_scores) if map_scores else 0.0\n",
    "precision_10 = sum(precision_10_scores) / len(precision_10_scores) if precision_10_scores else 0.0\n",
    "precision_50 = sum(precision_50_scores) / len(precision_50_scores) if precision_50_scores else 0.0\n",
    "\n",
    "# Print results\n",
    "print(\"Mean Average Precision (mAP):\", mean_avg_precision)\n",
    "print(\"Precision@10:\", precision_10)\n",
    "print(\"Precision@50:\", precision_50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
